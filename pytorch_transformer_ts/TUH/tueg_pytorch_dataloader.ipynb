{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Download TUAB\n",
    "# !rsync -auxvL --delete nedc-eeg@www.isip.piconepress.com:data/eeg/tuh_eeg_abnormal/ ./scratch/medical/eeg/tuab/ #you need the password see https://isip.piconepress.com/projects/tuh_eeg/html/downloads.shtml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download TUEG\n",
    "# !rsync -auxvL --delete nedc-eeg@www.isip.piconepress.com:data/eeg/tuh_eeg/ ./scratch/medical/eeg/tueg/ #you need the password see https://isip.piconepress.com/projects/tuh_eeg/html/downloads.shtml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip uninstall -y Braindecode \n",
    "!pip install git+https://github.com/MohammadJavadD/braindecode.git@f36c42c6e8281ad6e165f7ea3d5e65a9c73da308"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Process a big data EEG resource (TUH EEG Corpus)\n",
    "\n",
    "In this example, we showcase usage of the Temple University Hospital EEG Corpus\n",
    "(https://www.isip.piconepress.com/projects/tuh_eeg/html/downloads.shtml#c_tueg)\n",
    "including simple preprocessing steps as well as cutting of compute windows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Lukas Gemein <l.gemein@gmail.com>\n",
    "#\n",
    "# License: BSD (3-clause)\n",
    "\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from braindecode.datasets import TUH\n",
    "from braindecode.preprocessing import (\n",
    "    preprocess, Preprocessor, create_fixed_length_windows, scale as multiply)\n",
    "\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "mne.set_log_level('ERROR')  # avoid messages everytime a window is extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to try this code with the actual data, please delete the next\n",
    "section. We are required to mock some dataset functionality, since the data\n",
    "is not available at creation time of this example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datasets.tuh import  TUH  # noqa F811"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating a TUH dataset. First, the class generates a description\n",
    "of the recordings in `TUH_PATH` (which is later accessible as\n",
    "`tuh.description`) without actually touching the files. This will parse\n",
    "information from file paths such as patient id, recording data, etc and should\n",
    "be really fast. Afterwards, the files are sorted chronologically by year,\n",
    "month, day, patient id, recording session and segment.\n",
    "In the following, a subset of the description corresponding to `recording_ids`\n",
    "is used.\n",
    "Afterwards, the files will be iterated a second time, slower than before.\n",
    "The files are now actually touched. Additional information about subjects\n",
    "like age and gender are parsed directly from the EDF file header. If existent,\n",
    "the physician report is added to the description. Furthermore, the recordings\n",
    "are read with `mne.io.read_raw_edf` with `preload=False`. Finally, we will get\n",
    "a `BaseConcatDataset` of `BaseDatasets` each holding a single\n",
    "`nme.io.Raw` which is fully compatible with other braindecode functionalities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TUH_PATH = './scratch/medical/eeg/tueg_small/'\n",
    "N_JOBS = 4  # specify the number of jobs for loading and windowing\n",
    "tuh = TUH(\n",
    "    path=TUH_PATH,\n",
    "    recording_ids=None,\n",
    "    target_name=('age', 'gender'),  # use both age and gender as decoding target\n",
    "    preload=False,\n",
    "    add_physician_reports=False,\n",
    "    n_jobs=1 if TUH.__name__ == '_TUHMock' else N_JOBS,  # Mock dataset can't\n",
    "    # be loaded in parallel\n",
    ")\n",
    "tuh.description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily create descriptive statistics using the description `DataFrame`,\n",
    "for example an age histogram split by gender of patients.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "genders = tuh.description.gender.unique()\n",
    "x = [tuh.description.age[tuh.description.gender == g] for g in genders]\n",
    "ax.hist(\n",
    "    x=x,\n",
    "    stacked=True,\n",
    "    bins=np.arange(100, dtype=int),\n",
    "    alpha=.5,\n",
    ")\n",
    "ax.legend(genders)\n",
    "ax.set_xlabel('Age [years]')\n",
    "ax.set_ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will perform some preprocessing steps. First, we will do some\n",
    "selection of available recordings based on the duration. We will select those\n",
    "recordings, that have at least five minutes duration. Data is not loaded here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_by_duration(ds, tmin=0, tmax=None):\n",
    "    if tmax is None:\n",
    "        tmax = np.inf\n",
    "    # determine length of the recordings and select based on tmin and tmax\n",
    "    split_ids = []\n",
    "    for d_i, d in enumerate(ds.datasets):\n",
    "        duration = d.raw.n_times / d.raw.info['sfreq']\n",
    "        if tmin <= duration <= tmax:\n",
    "            split_ids.append(d_i)\n",
    "    splits = ds.split(split_ids)\n",
    "    split = splits['0']\n",
    "    return split\n",
    "\n",
    "\n",
    "tmin = 5 * 60\n",
    "tmax = None\n",
    "tuh = select_by_duration(tuh, tmin, tmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will discard all recordings that have an incomplete channel\n",
    "configuration (wrt the channels that we are interested in, i.e. the 21\n",
    "channels of the international 10-20-placement). The dataset is subdivided into\n",
    "recordings with 'le' and 'ar' reference which we will have to consider. Data\n",
    "is not loaded here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_ch_names = sorted([\n",
    "    'A1', 'A2',\n",
    "    'FP1', 'FP2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2',\n",
    "    'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'FZ', 'CZ', 'PZ'])\n",
    "ar_ch_names = sorted([\n",
    "    'EEG A1-REF', 'EEG A2-REF',\n",
    "    'EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF', 'EEG F4-REF', 'EEG C3-REF',\n",
    "    'EEG C4-REF', 'EEG P3-REF', 'EEG P4-REF', 'EEG O1-REF', 'EEG O2-REF',\n",
    "    'EEG F7-REF', 'EEG F8-REF', 'EEG T3-REF', 'EEG T4-REF', 'EEG T5-REF',\n",
    "    'EEG T6-REF', 'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF'])\n",
    "le_ch_names = sorted([\n",
    "    'EEG A1-LE', 'EEG A2-LE',\n",
    "    'EEG FP1-LE', 'EEG FP2-LE', 'EEG F3-LE', 'EEG F4-LE', 'EEG C3-LE',\n",
    "    'EEG C4-LE', 'EEG P3-LE', 'EEG P4-LE', 'EEG O1-LE', 'EEG O2-LE',\n",
    "    'EEG F7-LE', 'EEG F8-LE', 'EEG T3-LE', 'EEG T4-LE', 'EEG T5-LE',\n",
    "    'EEG T6-LE', 'EEG FZ-LE', 'EEG CZ-LE', 'EEG PZ-LE'])\n",
    "assert len(short_ch_names) == len(ar_ch_names) == len(le_ch_names)\n",
    "ar_ch_mapping = {ch_name: short_ch_name for ch_name, short_ch_name in zip(\n",
    "    ar_ch_names, short_ch_names)}\n",
    "le_ch_mapping = {ch_name: short_ch_name for ch_name, short_ch_name in zip(\n",
    "    le_ch_names, short_ch_names)}\n",
    "ch_mapping = {'ar': ar_ch_mapping, 'le': le_ch_mapping}\n",
    "\n",
    "\n",
    "def select_by_channels(ds, ch_mapping):\n",
    "    split_ids = []\n",
    "    for i, d in enumerate(ds.datasets):\n",
    "        ref = 'ar' if d.raw.ch_names[0].endswith('-REF') else 'le'\n",
    "        # these are the channels we are looking for\n",
    "        seta = set(ch_mapping[ref].keys())\n",
    "        # these are the channels of the recoding\n",
    "        setb = set(d.raw.ch_names)\n",
    "        # if recording contains all channels we are looking for, include it\n",
    "        if seta.issubset(setb):\n",
    "            split_ids.append(i)\n",
    "    return ds.split(split_ids)['0']\n",
    "\n",
    "\n",
    "tuh = select_by_channels(tuh, ch_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will chain several preprocessing steps that are realized through\n",
    "`mne`. Data will be loaded by the first preprocessor that has a mention of it\n",
    "in brackets:\n",
    "\n",
    "#. crop the recordings to a region of interest\n",
    "#. re-reference all recordings to 'ar' (requires load)\n",
    "#. rename channels to short channel names\n",
    "#. pick channels of interest\n",
    "#. scale signals to micro volts (requires load)\n",
    "#. clip outlier values to +/- 800 micro volts (requires load)\n",
    "#. resample recordings to a common frequency (requires load)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_rename_channels(raw, mapping):\n",
    "    # rename channels which are dependent on referencing:\n",
    "    # le: EEG 01-LE, ar: EEG 01-REF\n",
    "    # mne fails if the mapping contains channels as keys that are not present\n",
    "    # in the raw\n",
    "    reference = raw.ch_names[0].split('-')[-1].lower()\n",
    "    assert reference in ['le', 'ref'], 'unexpected referencing'\n",
    "    reference = 'le' if reference == 'le' else 'ar'\n",
    "    raw.rename_channels(mapping[reference])\n",
    "\n",
    "\n",
    "def custom_crop(raw, tmin=0.0, tmax=None, include_tmax=True):\n",
    "    # crop recordings to tmin â€“ tmax. can be incomplete if recording\n",
    "    # has lower duration than tmax\n",
    "    # by default mne fails if tmax is bigger than duration\n",
    "    tmax = min((raw.n_times - 1) / raw.info['sfreq'], tmax)\n",
    "    raw.crop(tmin=tmin, tmax=tmax, include_tmax=include_tmax)\n",
    "\n",
    "\n",
    "tmin = 1 * 60\n",
    "tmax = 6 * 60\n",
    "sfreq = 100\n",
    "\n",
    "preprocessors = [\n",
    "    Preprocessor(custom_crop, tmin=tmin, tmax=tmax, include_tmax=False,\n",
    "                 apply_on_array=False),\n",
    "    Preprocessor('set_eeg_reference', ref_channels='average', ch_type='eeg'),\n",
    "    Preprocessor(custom_rename_channels, mapping=ch_mapping,\n",
    "                 apply_on_array=False),\n",
    "    Preprocessor('pick_channels', ch_names=short_ch_names, ordered=True),\n",
    "    Preprocessor(multiply, factor=1e6, apply_on_array=True),\n",
    "    Preprocessor(np.clip, a_min=-800, a_max=800, apply_on_array=True),\n",
    "    Preprocessor('resample', sfreq=sfreq),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we apply the preprocessors on the selected recordings in parallel.\n",
    "We additionally use the serialization functionality of\n",
    ":func:`braindecode.preprocessing.preprocess` to limit memory usage during\n",
    "preprocessing (as each file must be loaded into memory for some of the\n",
    "preprocessing steps to work). This also makes it possible to use the lazy\n",
    "loading capabilities of :class:`braindecode.datasets.BaseConcatDataset`, as\n",
    "the preprocessed data is automatically reloaded with ``preload=False``.\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>Here we use ``n_jobs=2`` as the machines the documentation is build on\n",
    "   only have two cores. This number should be modified based on the machine\n",
    "   that is available for preprocessing.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH = tempfile.mkdtemp()  # please insert actual output directory here\n",
    "# from datetime import datetime\n",
    "# [ds_.raw.set_meas_date(datetime.now()) for ds_ in tuh.datasets]\n",
    "tuh_preproc = preprocess(\n",
    "    concat_ds=tuh,\n",
    "    preprocessors=preprocessors,\n",
    "    n_jobs=N_JOBS,\n",
    "    # save_dir=OUT_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally generate compute windows. The resulting dataset is now ready\n",
    "to be used for model training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size_samples = 1000\n",
    "window_stride_samples = 1000\n",
    "# generate compute windows here and store them to disk\n",
    "tuh_windows = create_fixed_length_windows(\n",
    "    tuh_preproc,\n",
    "    window_size_samples=window_size_samples,\n",
    "    window_stride_samples=window_stride_samples,\n",
    "    drop_last_window=False,\n",
    "    n_jobs=N_JOBS,\n",
    "    mapping={'M': 0, 'F': 1},  # map non-digit targets\n",
    "\n",
    ")\n",
    "# store the number of windows required for loading later on\n",
    "tuh_windows.set_description({\n",
    "    \"n_windows\": [len(d) for d in tuh_windows.datasets]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating through the dataset gives x as ndarray(n_channels x 1000), y as\n",
    "[age, gender], and ind. Let's look at the last example again.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, ind = tuh_windows[1]\n",
    "print('x shape:', x.shape)\n",
    "print('y:', y)\n",
    "print('ind:', ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We give the dataset to a pytorch DataLoader, such that it can be used for\n",
    "model training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(\n",
    "    dataset=tuh_windows,\n",
    "    batch_size=8,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating through the DataLoader gives batch_X as tensor(8 x n_channels x\n",
    "1000), batch_y as [tensor([8 x age of subject]), tensor([8 x gender of\n",
    "subject])], and batch_ind. We will iterate to the end to look at the last example\n",
    "again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_X, batch_y, batch_ind in dl:\n",
    "    # pass\n",
    "    print('batch_X shape:', batch_X.shape)\n",
    "    print('batch_y:', batch_y)\n",
    "    print('batch_ind:', batch_ind)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train a regressor to predict the age. Given EEG as the input and Age as the output. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3620a664c20541bdba91738e76685ba5fb065cca562da38b69039a2033111088"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
